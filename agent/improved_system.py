# Ulepszona implementacja systemu wieloagentowego
# Plik: agents/improved_system.py

import os
import re
from typing import Annotated, Literal, TypedDict, Dict, List
from datetime import datetime
import sqlite3
import pandas as pd

from langchain_openai import ChatOpenAI
from langchain_community.utilities.sql_database import SQLDatabase
from langchain.agents.agent_toolkits import SQLDatabaseToolkit
from langchain.tools import Tool
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage, AIMessage
from langgraph.graph import END, StateGraph
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode
from dotenv import load_dotenv

load_dotenv()

# ===== KONFIGURACJA =====
class Config:
    DB_PATH = r"/Users/fmpl5278/Desktop/Logi-projektTEG/parser/logs.db"
    DEFAULT_HOURLY_RATE = 150  # PLN/h - realistyczna stawka dla IT
    GOLD_PRICE_PLN = 280  # cena za gram
    BTC_PRICE_PLN = 180000
    USD_RATE = 4.05
    EUR_RATE = 4.30
    GBP_RATE = 5.10

# ===== INICJALIZACJA =====
llm = ChatOpenAI(
    model_name="gpt-4o-mini",
    openai_api_key=os.environ['OPENAI_API_KEY_TEG'],
    temperature=0,
)

sql_db = SQLDatabase.from_uri(f"sqlite:///{Config.DB_PATH}")
sql_toolkit = SQLDatabaseToolkit(db=sql_db, llm=llm)

# ===== ULEPSZONE NARZƒòDZIA =====

def calculate_comprehensive_loss(time_lost_seconds: int, hourly_rate: float = Config.DEFAULT_HOURLY_RATE) -> Dict:
    """
    Oblicza stratƒô w r√≥≈ºnych walutach i aktywach
    """
    hours = time_lost_seconds / 3600
    pln_loss = hours * hourly_rate
    
    return {
        "hours": round(hours, 2),
        "minutes": round((time_lost_seconds % 3600) / 60, 0),
        "pln": round(pln_loss, 2),
        "usd": round(pln_loss / Config.USD_RATE, 2),
        "eur": round(pln_loss / Config.EUR_RATE, 2),
        "gbp": round(pln_loss / Config.GBP_RATE, 2),
        "gold_grams": round(pln_loss / Config.GOLD_PRICE_PLN, 3),
        "btc": round(pln_loss / Config.BTC_PRICE_PLN, 6),
        "coffee_cups": round(pln_loss / 15, 0),  # ≈örednia cena kawy
        "netflix_months": round(pln_loss / 60, 1),  # Abonament Netflix
    }

def analyze_productivity_patterns(user: str = None, date_from: str = None, date_to: str = None) -> Dict:
    """
    Analizuje wzorce produktywno≈õci u≈ºytkownika lub zespo≈Çu
    """
    conn = sqlite3.connect(Config.DB_PATH)
    
    # Podstawowe zapytanie
    base_query = """
    SELECT 
        srcname,
        appcat,
        DATE(date) as day,
        strftime('%H', time) as hour,
        SUM(duration) as total_seconds,
        COUNT(*) as sessions
    FROM network_logs
    WHERE 1=1
    """
    
    # Dodaj filtry
    params = []
    if user:
        base_query += " AND srcname LIKE ?"
        params.append(f"%{user}%")
    
    if date_from:
        base_query += " AND date >= ?"
        params.append(date_from)
        
    if date_to:
        base_query += " AND date <= ?"
        params.append(date_to)
    
    base_query += " GROUP BY srcname, appcat, day, hour"
    
    df = pd.read_sql_query(base_query, conn, params=params)
    conn.close()
    
    # Analiza wzorc√≥w
    productivity_categories = ['Business', 'Development']
    unproductive_categories = ['Social.Media', 'Game', 'Adult']
    
    productive_time = df[df['appcat'].isin(productivity_categories)]['total_seconds'].sum()
    unproductive_time = df[df['appcat'].isin(unproductive_categories)]['total_seconds'].sum()
    
    # Najgorsze godziny
    worst_hours = df[df['appcat'].isin(unproductive_categories)].groupby('hour')['total_seconds'].sum().nlargest(3)
    
    return {
        "productive_hours": round(productive_time / 3600, 2),
        "unproductive_hours": round(unproductive_time / 3600, 2),
        "productivity_ratio": round(productive_time / (productive_time + unproductive_time) if (productive_time + unproductive_time) > 0 else 0, 2),
        "worst_hours": worst_hours.to_dict(),
        "total_users": df['srcname'].nunique(),
        "most_used_unproductive_app": df[df['appcat'].isin(unproductive_categories)].groupby('appcat')['total_seconds'].sum().idxmax() if not df[df['appcat'].isin(unproductive_categories)].empty else None
    }

def get_user_summary(identifier: str) -> str:
    """
    Pobiera podsumowanie aktywno≈õci u≈ºytkownika na podstawie nazwy, IP lub MAC
    """
    conn = sqlite3.connect(Config.DB_PATH)
    
    # Sprawd≈∫ czy to MAC, IP czy nazwa
    if re.match(r'^([0-9A-Fa-f]{2}[:-]){5}([0-9A-Fa-f]{2})$', identifier):
        condition = "mastersrcmac = ?"
    elif re.match(r'^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}$', identifier):
        condition = "srcip = ?"
    else:
        condition = "srcname LIKE ?"
        identifier = f"%{identifier}%"
    
    query = f"""
    SELECT 
        srcname,
        srcip,
        mastersrcmac,
        appcat,
        app,
        SUM(duration) as total_seconds,
        COUNT(*) as sessions,
        AVG(sentbyte + rcvdbyte) as avg_traffic
    FROM network_logs
    WHERE {condition}
    GROUP BY srcname, srcip, mastersrcmac, appcat, app
    ORDER BY total_seconds DESC
    """
    
    df = pd.read_sql_query(query, conn, params=[identifier])
    conn.close()
    
    if df.empty:
        return "Nie znaleziono u≈ºytkownika"
    
    # Formatuj wyniki
    user_info = df.iloc[0]
    summary = f"U≈ºytkownik: {user_info['srcname']} (IP: {user_info['srcip']}, MAC: {user_info['mastersrcmac']})\n\n"
    summary += "Top 5 aplikacji:\n"
    
    for _, row in df.head(5).iterrows():
        hours = row['total_seconds'] / 3600
        summary += f"- {row['app']} ({row['appcat']}): {hours:.1f}h w {row['sessions']} sesjach\n"
    
    return summary

# ===== ULEPSZONE PROMPTY =====

SEARCH_PROMPT = """Jeste≈õ ekspertem SQL analizujƒÖcym logi sieciowe. Twoje zadanie to konwersja pyta≈Ñ u≈ºytkownika na zapytania SQL.

STRUKTURA TABELI network_logs:
- date (DATE): data zdarzenia
- time (TIME): czas zdarzenia  
- srcname (TEXT): nazwa u≈ºytkownika
- srcip (TEXT): IP ≈∫r√≥d≈Çowe
- mastersrcmac (TEXT): adres MAC
- app (TEXT): nazwa aplikacji
- appcat (TEXT): kategoria (Social.Media, Game, Adult, Business, Development)
- duration (INTEGER): czas trwania w SEKUNDACH
- action (TEXT): typ akcji (close, open, etc.)
- sentbyte, rcvdbyte: transfer danych

WA≈ªNE ZASADY:
1. Duration jest w SEKUNDACH - pamiƒôtaj o konwersji na godziny/minuty
2. U≈ºywaj LIKE dla wyszukiwania czƒô≈õciowego (np. srcname LIKE '%Dawid%')
3. Daty formatuj jako 'YYYY-MM-DD'
4. Zawsze u≈ºywaj GROUP BY gdy u≈ºywasz funkcji agregujƒÖcych
5. Dla MAC adres√≥w u≈ºywaj dok≈Çadnego dopasowania

PRZYK≈ÅADY:
- "Ile czasu Dawid spƒôdzi≈Ç na FB?" ‚Üí SELECT srcname, app, SUM(duration) as total_seconds FROM network_logs WHERE srcname LIKE '%Dawid%' AND app LIKE '%Facebook%' GROUP BY srcname, app
- "Kto najwiƒôcej gra?" ‚Üí SELECT srcname, SUM(duration) as total_seconds FROM network_logs WHERE appcat = 'Game' GROUP BY srcname ORDER BY total_seconds DESC LIMIT 10

Generuj TYLKO zapytanie SQL, bez dodatkowych komentarzy."""

VALUE_PROMPT = """Jeste≈õ agentem finansowym. Otrzymujesz dane o czasie (w sekundach) i obliczasz straty finansowe.

STAWKI:
- Godzinowa: 150 PLN (≈õrednia w IT)
- Kawa: 15 PLN
- Netflix: 60 PLN/miesiƒÖc
- Gram z≈Çota: 280 PLN
- Bitcoin: 180,000 PLN

Przedstaw wyniki w czytelny spos√≥b, np.:
"Stracony czas: X godzin Y minut
Koszt: Z PLN (r√≥wnowarto≈õƒá A kaw lub B gram√≥w z≈Çota)"

U≈ºywaj praktycznych por√≥wna≈Ñ, kt√≥re pomogƒÖ zrozumieƒá skalƒô straty."""

NATURAL_PROMPT = """Jeste≈õ asystentem analizujƒÖcym ruch sieciowy. Otrzymujesz wyniki zapyta≈Ñ SQL i przekszta≈Çcasz je w przyjazne odpowiedzi.

ZASADY:
1. U≈ºywaj prostego, zrozumia≈Çego jƒôzyka
2. Konwertuj sekundy na godziny i minuty (np. 3665 sekund = 1 godzina 1 minuta)
3. Grupuj dane logicznie (np. po kategoriach aplikacji)
4. Dodawaj kontekst (np. "To stanowi 20% czasu pracy")
5. U≈ºywaj emotikon√≥w dla lepszej czytelno≈õci üìä

PRZYK≈ÅAD:
Zamiast: "duration: 7200"
Napisz: "Spƒôdzi≈Ç 2 godziny na tej aplikacji üïê"
"""

# ===== ULEPSZONE NARZƒòDZIA =====

tools = [
    Tool.from_function(
        func=calculate_comprehensive_loss,
        name="calculate_loss",
        description="Oblicza straty w r√≥≈ºnych walutach. Wymaga: time_lost_seconds (int), opcjonalnie hourly_rate (float)"
    ),
    Tool.from_function(
        func=analyze_productivity_patterns,
        name="analyze_productivity",
        description="Analizuje wzorce produktywno≈õci. Parametry: user (str), date_from (YYYY-MM-DD), date_to (YYYY-MM-DD)"
    ),
    Tool.from_function(
        func=get_user_summary,
        name="get_user_summary",
        description="Pobiera podsumowanie u≈ºytkownika. Parametr: identifier (nazwa/IP/MAC)"
    ),
] + sql_toolkit.get_tools()

# ===== ULEPSZONE WƒòZ≈ÅY =====

class ImprovedAgentState(TypedDict):
    messages: Annotated[list, add_messages]
    no_of_iterations: int
    sql_query: str  # Przechowuj zapytanie SQL
    raw_data: str   # Przechowuj surowe dane
    context: Dict   # Kontekst dla lepszego zrozumienia

def improved_search_node(state):
    """Ulepszona wersja search node z lepszym debugowaniem"""
    print(f"\n[SEARCH] Otrzymane pytanie: {state['messages'][-1].content}")
    
    # WyciƒÖgnij kontekst z pytania
    question = state['messages'][-1].content.lower()
    context = {
        "has_time_query": any(word in question for word in ['czas', 'godzin', 'minut', 'spƒôdzi≈Ç', 'straci≈Ç']),
        "has_user_query": any(word in question for word in ['u≈ºytkownik', 'kto', 'osoba']),
        "has_cost_query": any(word in question for word in ['koszt', 'straci≈Ç', 'pieniƒÖdze', 'z≈Çoto', 'btc']),
        "time_period": extract_time_period(question)
    }
    
    result = search_agent.invoke(state)
    
    # Zapisz zapytanie SQL
    sql_query = extract_sql_from_response(result.content)
    
    return {
        "messages": state["messages"] + [result],
        "no_of_iterations": state["no_of_iterations"] + 1,
        "sql_query": sql_query,
        "context": context
    }

def extract_time_period(question: str) -> str:
    """WyciƒÖga okres czasu z pytania"""
    if "dzisiaj" in question:
        return datetime.now().strftime("%Y-%m-%d")
    elif "wczoraj" in question:
        return (datetime.now() - pd.Timedelta(days=1)).strftime("%Y-%m-%d")
    elif "tydzie≈Ñ" in question or "tygodniu" in question:
        return "last_week"
    elif "miesiƒÖc" in question or "miesiƒÖcu" in question:
        return "last_month"
    return "all_time"

def extract_sql_from_response(response: str) -> str:
    """WyciƒÖga czyste SQL z odpowiedzi"""
    # Usu≈Ñ markdown i inne ≈õmieci
    sql = response.strip()
    sql = re.sub(r'```sql\s*', '', sql)
    sql = re.sub(r'```\s*', '', sql)
    sql = re.sub(r'SQLQuery:\s*', '', sql, flags=re.IGNORECASE)
    return sql.strip()

# ===== KONFIGURACJA AGENT√ìW =====

def create_improved_agent(llm, tools, system_message: str):
    """Tworzy agenta z ulepszonym promptem"""
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_message),
        MessagesPlaceholder(variable_name="messages"),
    ])
    
    if tools:
        return prompt | llm.bind_tools(tools)
    return prompt | llm

# Tworzenie agent√≥w
search_agent = create_improved_agent(llm, tools, SEARCH_PROMPT)
value_agent = create_improved_agent(llm, tools, VALUE_PROMPT)
natural_agent = create_improved_agent(llm, [], NATURAL_PROMPT)

# ===== BUDOWA GRAFU =====

workflow = StateGraph(ImprovedAgentState)

# Dodaj wƒôz≈Çy
workflow.add_node("search", improved_search_node)
workflow.add_node("tools", ToolNode(tools))
workflow.add_node("natural", natural_response_node)
workflow.add_node("value", value_node)

# Ustaw przep≈Çyw
workflow.set_entry_point("search")
workflow.add_edge("search", "tools")
workflow.add_edge("tools", "natural")

# Warunkowa krawƒôd≈∫ - czy potrzebna analiza koszt√≥w?
def should_calculate_cost(state) -> Literal["value", "end"]:
    context = state.get("context", {})
    last_message = state["messages"][-1].content.lower()
    
    if context.get("has_cost_query") or context.get("has_time_query"):
        return "value"
    return "end"

workflow.add_conditional_edges(
    "natural",
    should_calculate_cost,
    {
        "value": "value",
        "end": END
    }
)

workflow.add_edge("value", END)

# Kompiluj graf
graph = workflow.compile()

# ===== FUNKCJE POMOCNICZE =====

def run_query(question: str):
    """Uruchamia zapytanie i zwraca sformatowanƒÖ odpowied≈∫"""
    print(f"\n{'='*60}")
    print(f"PYTANIE: {question}")
    print(f"{'='*60}")
    
    input_data = {
        "messages": [HumanMessage(content=question)],
        "no_of_iterations": 0,
        "sql_query": "",
        "raw_data": "",
        "context": {}
    }
    
    # Zbierz wszystkie kroki
    steps = []
    for event in graph.stream(input_data, stream_mode="values"):
        steps.append(event)
    
    # WyciƒÖgnij ko≈ÑcowƒÖ odpowied≈∫
    final_messages = steps[-1]["messages"]
    
    # Formatuj odpowied≈∫
    response = {
        "question": question,
        "sql_query": steps[-1].get("sql_query", ""),
        "answer": final_messages[-1].content if final_messages else "Brak odpowiedzi",
        "steps": len(steps),
        "context": steps[-1].get("context", {})
    }
    
    return response

# ===== PRZYK≈ÅADY U≈ªYCIA =====

if __name__ == "__main__":
    # Przyk≈Çadowe zapytania
    test_queries = [
        "Ile czasu Dawid spƒôdzi≈Ç na Facebooku w tym tygodniu?",
        "Kto najwiƒôcej gra w godzinach pracy? Poka≈º top 5 os√≥b",
        "Ile pieniƒôdzy stracili≈õmy na social media wczoraj?",
        "Poka≈º mi aktywno≈õƒá u≈ºytkownika o MAC 1e:ea:73:e5:55:b0",
        "Jaka jest produktywno≈õƒá zespo≈Çu w tym miesiƒÖcu?",
    ]
    
    for query in test_queries:
        result = run_query(query)
        print(f"\nODPOWIED≈π:\n{result['answer']}\n")
        if result['sql_query']:
            print(f"SQL: {result['sql_query']}\n")